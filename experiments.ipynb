{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from agents import GlobalConsensus, EventGlobalConsensus, EventGlobalConsensusTorch\n",
    "from models import NN, Dummy\n",
    "from utils import add_params, scale_params, subtract_params\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- model 1 -----\n",
      "Parameter containing:\n",
      "tensor([[0.7851]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.7002], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.1879]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.2036], requires_grad=True)\n",
      "\n",
      "----- model 2 -----\n",
      "Parameter containing:\n",
      "tensor([[-0.4236]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.8657], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5011]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5872], requires_grad=True)\n",
      "\n",
      "Output before weight adjustments : tensor([0.2195], grad_fn=<AddBackward0>)\n",
      "\n",
      "----- model adjusted -----\n",
      "Parameter containing:\n",
      "tensor([[1.5702]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1.4004], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.3759]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4072], requires_grad=True)\n",
      "\n",
      "Output after weight adjustments : tensor([0.4710], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model1 = NN(1,1,1)\n",
    "model2 = NN(1,1,1)\n",
    "a = torch.tensor([1.])\n",
    "\n",
    "print('----- model 1 -----')\n",
    "for param in model1.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n----- model 2 -----')\n",
    "for param in model2.parameters():\n",
    "    print(param)\n",
    "\n",
    "print(f'\\nOutput before weight adjustments : {model1(a)}')\n",
    "\n",
    "print('\\n----- model adjusted -----')\n",
    "copy_of_params = model1.parameters()\n",
    "scale_params(copy_of_params, a=2)\n",
    "# new_params = add_params(new_params, model2.parameters())\n",
    "for param in model1.parameters():\n",
    "    print(param)\n",
    "\n",
    "print(f'\\nOutput after weight adjustments : {model1(a)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADMM Global Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.66627408 0.36283321]\n",
      "[-0.62562115 -1.06675469]\n",
      "[-0.87154073 -1.16677911]\n",
      "[-0.85410717 -0.75969017]\n",
      "average = [-0.17124875 -0.65759769]\n"
     ]
    }
   ],
   "source": [
    "rho = 1\n",
    "\n",
    "# Initial lambdas must sum to 0!\n",
    "lam = np.random.randn(2,2)\n",
    "lambdas = np.vstack([lam, -lam])\n",
    "\n",
    "agents = [\n",
    "    GlobalConsensus(\n",
    "        rho=rho, \n",
    "        x_init=np.random.randn(2), \n",
    "        lam_init=lam\n",
    "    ) \n",
    "    for lam in lambdas\n",
    "]\n",
    "\n",
    "# comopute initial average\n",
    "avg = 0\n",
    "for agent in agents:\n",
    "    avg += agent.x/len(agents) \n",
    "\n",
    "# broadcast average to all agents\n",
    "for agent in agents:\n",
    "    agent.primal_average = avg\n",
    "    print(agent.x)\n",
    "print(f'average = {agents[0].primal_average}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent 0: x = [-9.29896088e-10  2.54475796e-10], lam = [ 1.85979218e-09 -5.08951591e-10]\n",
      "agent 1: x = [-9.95162857e-11 -2.62032839e-10], lam = [1.99032571e-10 5.24065679e-10]\n",
      "agent 2: x = [ 9.29896088e-10 -2.54475796e-10], lam = [-1.85979218e-09  5.08951591e-10]\n",
      "agent 3: x = [9.95162857e-11 2.62032839e-10], lam = [-1.99032571e-10 -5.24065679e-10]\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    # compute primal variables\n",
    "    for agent in agents:\n",
    "        agent.primal_update()\n",
    "\n",
    "    # compute new global average\n",
    "    avg = 0\n",
    "    for agent in agents:\n",
    "        avg += agent.x/len(agents) \n",
    "    \n",
    "    # broadcast average to all agents\n",
    "    for agent in agents:\n",
    "        agent.primal_average = avg\n",
    "\n",
    "    # update dual variables    \n",
    "    for agent in agents:\n",
    "        agent.dual_update()\n",
    "\n",
    "for i, agent in enumerate(agents):\n",
    "    print(f'agent {i}: x = {agent.x}, lam = {agent.lam}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event-Based ADMM Global Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 1\n",
    "\n",
    "deltas = [0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7]\n",
    "deltas = [1e-5]\n",
    "t_max = 100\n",
    "\n",
    "# Initial lambdas must sum to 0!\n",
    "lam = np.random.randn(2,2)*5\n",
    "lambdas = np.vstack([lam, -lam])\n",
    "x_init = np.random.randn(lambdas.shape[0],2)*5\n",
    "initial_avg = np.mean(x_init, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.000000, load = 0.3\n"
     ]
    }
   ],
   "source": [
    "for delta in deltas:\n",
    "\n",
    "    # Initialise Agents\n",
    "    agents = [\n",
    "        EventGlobalConsensus(\n",
    "            N = len(lambdas), \n",
    "            rho=rho, \n",
    "            delta=delta,\n",
    "            x_init=x, \n",
    "            lam_init=lam\n",
    "        ) \n",
    "        for lam, x in zip(lambdas, x_init)\n",
    "    ]\n",
    "\n",
    "    # broadcast average to all agents\n",
    "    for agent in agents:\n",
    "        agent.primal_avg = initial_avg\n",
    "\n",
    "    # Run event based ADMM\n",
    "    comm = 0\n",
    "\n",
    "    for t in range(t_max):\n",
    "        \n",
    "        for agent in agents:\n",
    "            agent.primal_update()\n",
    "        \n",
    "        sum_of_res = 0\n",
    "        for agent in agents:\n",
    "            if agent.broadcast: \n",
    "                comm += 1\n",
    "                sum_of_res += agent.residual\n",
    "            \n",
    "        # This is somehow updating all the agents\n",
    "        agent.primal_avg += sum_of_res\n",
    "        \n",
    "        for agent in agents:\n",
    "            agent.dual_update()\n",
    "    \n",
    "    accuracy = np.sum([np.linalg.norm(agent.x - agent.C, ord=1) for agent in agents])\n",
    "    \n",
    "    load = comm/(t_max*len(agents))\n",
    "    print(f'Accuracy = {accuracy:.6f}, load = {load}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event-Based ADMM with Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta\n",
    "t_max = 25\n",
    "\n",
    "# Initial lambdas must sum to 0!\n",
    "lam = np.random.randn(2,2)*5\n",
    "lambdas = np.vstack([lam, -lam])\n",
    "x_init = np.random.randn(lambdas.shape[0],2)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dummy.__init__() missing 1 required positional argument: 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaelcummins/ADMM/experiments.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agents \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     EventGlobalConsensusTorch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         N \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lambdas), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         rho\u001b[39m=\u001b[39mrho, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         model\u001b[39m=\u001b[39mDummy,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         loss\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mnorm,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         delta\u001b[39m=\u001b[39mdelta,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         x_init\u001b[39m=\u001b[39mx, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         lam_init\u001b[39m=\u001b[39mlam\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m lam, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(lambdas, x_init)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m ]\n",
      "\u001b[1;32m/Users/michaelcummins/ADMM/experiments.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agents \u001b[39m=\u001b[39m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     EventGlobalConsensusTorch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         N \u001b[39m=\u001b[39;49m \u001b[39mlen\u001b[39;49m(lambdas), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         rho\u001b[39m=\u001b[39;49mrho, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         model\u001b[39m=\u001b[39;49mDummy,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         loss\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mnorm,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         delta\u001b[39m=\u001b[39;49mdelta,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         x_init\u001b[39m=\u001b[39;49mx, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         lam_init\u001b[39m=\u001b[39;49mlam\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m lam, x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(lambdas, x_init)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelcummins/ADMM/experiments.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m ]\n",
      "File \u001b[0;32m~/ADMM/agents.py:88\u001b[0m, in \u001b[0;36mEventGlobalConsensusTorch.__init__\u001b[0;34m(self, rho, N, delta, model, loss, x_init, lam_init, z_init, nu_init)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mlam_init is a generator containting dual parameters, not a model -> similar to model.parameters()\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[39mx_init is a generator containting dual parameters, not a model -> similar to model.parameters()\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39mIf a model is passed - the parameters should be initialised within the model rather than passing x_init\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[39mself.primal_avg is also represented as a generator containing model parameters\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model()\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m loss\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, weight_decay\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrho)\n",
      "\u001b[0;31mTypeError\u001b[0m: Dummy.__init__() missing 1 required positional argument: 'x'"
     ]
    }
   ],
   "source": [
    "agents = [\n",
    "    EventGlobalConsensusTorch(\n",
    "        N = len(lambdas), \n",
    "        rho=rho, \n",
    "        model=Dummy,\n",
    "        loss=torch.norm,\n",
    "        delta=delta,\n",
    "        x_init=x, \n",
    "        lam_init=lam\n",
    "    ) \n",
    "    for lam, x in zip(lambdas, x_init)\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepc-hunt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
